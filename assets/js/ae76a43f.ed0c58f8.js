"use strict";(globalThis.webpackChunkagentops_docs=globalThis.webpackChunkagentops_docs||[]).push([[166],{2071(e){e.exports=JSON.parse('{"permalink":"/agentops-ai/blog/langchain-observability-complete-guide","editUrl":"https://github.com/agentops/agentops-docs/tree/main/blog/2024-04-12-langchain-observability.md","source":"@site/blog/2024-04-12-langchain-observability.md","title":"LangChain + AgentOps: Complete Observability Guide","description":"Learn how to add full observability to your LangChain agents with AgentOps. Step-by-step guide with examples.","date":"2024-04-12T00:00:00.000Z","tags":[{"inline":true,"label":"langchain","permalink":"/agentops-ai/blog/tags/langchain"},{"inline":true,"label":"integration","permalink":"/agentops-ai/blog/tags/integration"},{"inline":true,"label":"tutorial","permalink":"/agentops-ai/blog/tags/tutorial"},{"inline":true,"label":"observability","permalink":"/agentops-ai/blog/tags/observability"}],"readingTime":7.05,"hasTruncateMarker":true,"authors":[{"name":"Emily Zhang","title":"Developer Advocate at AgentOps","url":"https://github.com/emilyzhang","image_url":"https://images.unsplash.com/photo-1580489944761-15a19d654956?w=150&h=150&fit=crop&crop=face","imageURL":"https://images.unsplash.com/photo-1580489944761-15a19d654956?w=150&h=150&fit=crop&crop=face","socials":{},"key":null,"page":null}],"frontMatter":{"slug":"langchain-observability-complete-guide","title":"LangChain + AgentOps: Complete Observability Guide","authors":[{"name":"Emily Zhang","title":"Developer Advocate at AgentOps","url":"https://github.com/emilyzhang","image_url":"https://images.unsplash.com/photo-1580489944761-15a19d654956?w=150&h=150&fit=crop&crop=face","imageURL":"https://images.unsplash.com/photo-1580489944761-15a19d654956?w=150&h=150&fit=crop&crop=face"}],"tags":["langchain","integration","tutorial","observability"],"description":"Learn how to add full observability to your LangChain agents with AgentOps. Step-by-step guide with examples.","image":"https://images.unsplash.com/photo-1639322537228-f710d846310a?w=1200&h=630&fit=crop"},"unlisted":false,"prevItem":{"title":"Building Production-Ready AI Agents: A Complete Checklist","permalink":"/agentops-ai/blog/building-production-ready-ai-agents"},"nextItem":{"title":"The Complete Guide to LLM Cost Optimization for AI Agents","permalink":"/agentops-ai/blog/cost-optimization-llm-agents"}}')},7801(e,n,t){t.r(n),t.d(n,{assets:()=>l,contentTitle:()=>o,default:()=>d,frontMatter:()=>r,metadata:()=>s,toc:()=>c});var s=t(2071),a=t(4848),i=t(8453);const r={slug:"langchain-observability-complete-guide",title:"LangChain + AgentOps: Complete Observability Guide",authors:[{name:"Emily Zhang",title:"Developer Advocate at AgentOps",url:"https://github.com/emilyzhang",image_url:"https://images.unsplash.com/photo-1580489944761-15a19d654956?w=150&h=150&fit=crop&crop=face"}],tags:["langchain","integration","tutorial","observability"],description:"Learn how to add full observability to your LangChain agents with AgentOps. Step-by-step guide with examples.",image:"https://images.unsplash.com/photo-1639322537228-f710d846310a?w=1200&h=630&fit=crop"},o="LangChain + AgentOps: Complete Observability Guide",l={authorsImageUrls:[void 0]},c=[{value:"Why Observability Matters for LangChain",id:"why-observability-matters-for-langchain",level:2},{value:"Quick Setup",id:"quick-setup",level:2},{value:"Deep Dive: What Gets Tracked",id:"deep-dive-what-gets-tracked",level:2},{value:"LLM Calls",id:"llm-calls",level:3},{value:"Tool Executions",id:"tool-executions",level:3},{value:"Agent Reasoning",id:"agent-reasoning",level:3},{value:"Advanced Integration Patterns",id:"advanced-integration-patterns",level:2},{value:"Custom Callbacks",id:"custom-callbacks",level:3},{value:"Tracking RAG Pipelines",id:"tracking-rag-pipelines",level:3},{value:"Multi-Chain Workflows",id:"multi-chain-workflows",level:3},{value:"Debugging Common Issues",id:"debugging-common-issues",level:2},{value:"Issue 1: Agent Loops",id:"issue-1-agent-loops",level:3},{value:"Issue 2: High Latency",id:"issue-2-high-latency",level:3},{value:"Issue 3: Unexpected Costs",id:"issue-3-unexpected-costs",level:3},{value:"Best Practices",id:"best-practices",level:2},{value:"1. Use Meaningful Tags",id:"1-use-meaningful-tags",level:3},{value:"2. Record Business Events",id:"2-record-business-events",level:3},{value:"3. Set Up Alerts",id:"3-set-up-alerts",level:3},{value:"Real-World Example",id:"real-world-example",level:2}];function p(e){const n={a:"a",code:"code",em:"em",h2:"h2",h3:"h3",hr:"hr",img:"img",li:"li",mermaid:"mermaid",p:"p",pre:"pre",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",ul:"ul",...(0,i.R)(),...e.components};return(0,a.jsxs)(a.Fragment,{children:[(0,a.jsx)(n.p,{children:(0,a.jsx)(n.img,{src:"https://images.unsplash.com/photo-1639322537228-f710d846310a?w=1200&h=400&fit=crop",alt:"LangChain Observability"})}),"\n",(0,a.jsx)(n.p,{children:"LangChain is one of the most popular frameworks for building AI agents, but debugging LangChain applications can be challenging. This guide shows you how to add comprehensive observability to your LangChain agents using AgentOps."}),"\n",(0,a.jsx)(n.h2,{id:"why-observability-matters-for-langchain",children:"Why Observability Matters for LangChain"}),"\n",(0,a.jsx)(n.p,{children:"LangChain applications involve multiple components working together:"}),"\n",(0,a.jsx)(n.mermaid,{value:'flowchart TB\n    subgraph "LangChain Application"\n        A[User Input] --\x3e B[Prompt Template]\n        B --\x3e C[LLM]\n        C --\x3e D{Agent Decision}\n        D --\x3e|Tool Call| E[Tool Executor]\n        E --\x3e F[Tool 1: Search]\n        E --\x3e G[Tool 2: Calculator]\n        E --\x3e H[Tool 3: Database]\n        F --\x3e D\n        G --\x3e D\n        H --\x3e D\n        D --\x3e|Final Answer| I[Output Parser]\n        I --\x3e J[Response]\n    end\n\n    style C fill:#0066FF,stroke:#3399FF,color:#fff\n    style E fill:#22C55E,stroke:#16A34A,color:#fff\n    style D fill:#F59E0B,stroke:#D97706,color:#fff'}),"\n",(0,a.jsx)(n.p,{children:"Without observability, you're flying blind. You can't see:"}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsx)(n.li,{children:"Which tools are being called and why"}),"\n",(0,a.jsx)(n.li,{children:"How much each LLM call costs"}),"\n",(0,a.jsx)(n.li,{children:"Where bottlenecks occur in the chain"}),"\n",(0,a.jsx)(n.li,{children:"Why the agent made certain decisions"}),"\n"]}),"\n",(0,a.jsx)(n.h2,{id:"quick-setup",children:"Quick Setup"}),"\n",(0,a.jsx)(n.p,{children:"Getting started takes just two lines of code:"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:'import agentops\nagentops.init(api_key="your-api-key")\n\n# Your existing LangChain code works unchanged!\nfrom langchain.agents import create_openai_functions_agent, AgentExecutor\nfrom langchain_openai import ChatOpenAI\nfrom langchain.tools import tool\n\n@tool\ndef search_web(query: str) -> str:\n    """Search the web for information."""\n    # Your search implementation\n    return f"Results for: {query}"\n\nllm = ChatOpenAI(model="gpt-4")\nagent = create_openai_functions_agent(llm, [search_web], prompt)\nexecutor = AgentExecutor(agent=agent, tools=[search_web])\n\n# AgentOps automatically tracks everything!\nresult = executor.invoke({"input": "What\'s the weather in Tokyo?"})\n'})}),"\n",(0,a.jsx)(n.p,{children:"That's it! AgentOps automatically instruments:"}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsx)(n.li,{children:"All LLM calls with prompts and responses"}),"\n",(0,a.jsx)(n.li,{children:"Tool invocations with inputs and outputs"}),"\n",(0,a.jsx)(n.li,{children:"Agent reasoning steps"}),"\n",(0,a.jsx)(n.li,{children:"Token usage and costs"}),"\n"]}),"\n",(0,a.jsx)(n.h2,{id:"deep-dive-what-gets-tracked",children:"Deep Dive: What Gets Tracked"}),"\n",(0,a.jsx)(n.h3,{id:"llm-calls",children:"LLM Calls"}),"\n",(0,a.jsx)(n.p,{children:"Every call to the LLM is captured with full context:"}),"\n",(0,a.jsx)(n.mermaid,{value:"sequenceDiagram\n    participant App as LangChain App\n    participant AO as AgentOps\n    participant LLM as OpenAI\n\n    App->>AO: Start tracking\n    App->>LLM: chat.completions.create()\n    Note over AO: Captures: model, messages,<br/>temperature, tokens\n    LLM--\x3e>App: Response\n    Note over AO: Captures: response content,<br/>finish reason, usage\n    AO->>AO: Calculate cost\n    App->>AO: End tracking"}),"\n",(0,a.jsx)(n.p,{children:"In the AgentOps dashboard, you see:"}),"\n",(0,a.jsxs)(n.table,{children:[(0,a.jsx)(n.thead,{children:(0,a.jsxs)(n.tr,{children:[(0,a.jsx)(n.th,{children:"Metric"}),(0,a.jsx)(n.th,{children:"Example Value"})]})}),(0,a.jsxs)(n.tbody,{children:[(0,a.jsxs)(n.tr,{children:[(0,a.jsx)(n.td,{children:"Model"}),(0,a.jsx)(n.td,{children:"gpt-4-0125-preview"})]}),(0,a.jsxs)(n.tr,{children:[(0,a.jsx)(n.td,{children:"Input Tokens"}),(0,a.jsx)(n.td,{children:"1,234"})]}),(0,a.jsxs)(n.tr,{children:[(0,a.jsx)(n.td,{children:"Output Tokens"}),(0,a.jsx)(n.td,{children:"567"})]}),(0,a.jsxs)(n.tr,{children:[(0,a.jsx)(n.td,{children:"Latency"}),(0,a.jsx)(n.td,{children:"2.3s"})]}),(0,a.jsxs)(n.tr,{children:[(0,a.jsx)(n.td,{children:"Cost"}),(0,a.jsx)(n.td,{children:"$0.0456"})]}),(0,a.jsxs)(n.tr,{children:[(0,a.jsx)(n.td,{children:"Prompt"}),(0,a.jsx)(n.td,{children:'"You are a helpful assistant..."'})]}),(0,a.jsxs)(n.tr,{children:[(0,a.jsx)(n.td,{children:"Response"}),(0,a.jsx)(n.td,{children:'"Based on my search..."'})]})]})]}),"\n",(0,a.jsx)(n.h3,{id:"tool-executions",children:"Tool Executions"}),"\n",(0,a.jsx)(n.p,{children:"Tool calls are tracked with timing and results:"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:'from langchain.tools import tool\nfrom agentops import ActionEvent\n\n@tool\ndef database_query(query: str) -> str:\n    """Execute a database query and return results."""\n    # AgentOps automatically tracks this tool execution\n    # But you can add custom events for more detail:\n\n    agentops.record(ActionEvent(\n        action_type="database_query",\n        params={\n            "query": query,\n            "table": extract_table_name(query)\n        }\n    ))\n\n    results = execute_query(query)\n\n    agentops.record(ActionEvent(\n        action_type="database_result",\n        params={\n            "row_count": len(results),\n            "columns": list(results.columns)\n        }\n    ))\n\n    return results.to_string()\n'})}),"\n",(0,a.jsx)(n.h3,{id:"agent-reasoning",children:"Agent Reasoning"}),"\n",(0,a.jsx)(n.p,{children:"See exactly how your agent thinks:"}),"\n",(0,a.jsx)(n.mermaid,{value:'flowchart TD\n    A["User: What\'s the capital of France<br/>and its population?"] --\x3e B[Agent Reasoning]\n\n    B --\x3e C["Thought: I need to find two pieces<br/>of information"]\n    C --\x3e D["Action: search_web"]\n    D --\x3e E["Input: capital of France"]\n    E --\x3e F["Observation: Paris is the capital"]\n\n    F --\x3e G["Thought: Now I need the population"]\n    G --\x3e H["Action: search_web"]\n    H --\x3e I["Input: population of Paris"]\n    I --\x3e J["Observation: 2.1 million"]\n\n    J --\x3e K["Thought: I have both answers"]\n    K --\x3e L["Final Answer: Paris, 2.1 million"]\n\n    style A fill:#0066FF,stroke:#3399FF,color:#fff\n    style L fill:#22C55E,stroke:#16A34A,color:#fff'}),"\n",(0,a.jsx)(n.h2,{id:"advanced-integration-patterns",children:"Advanced Integration Patterns"}),"\n",(0,a.jsx)(n.h3,{id:"custom-callbacks",children:"Custom Callbacks"}),"\n",(0,a.jsx)(n.p,{children:"For fine-grained control, use custom callbacks:"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:'from langchain.callbacks.base import BaseCallbackHandler\nfrom agentops import ActionEvent\n\nclass AgentOpsCallback(BaseCallbackHandler):\n    """Custom callback for detailed AgentOps integration."""\n\n    def on_chain_start(self, serialized, inputs, **kwargs):\n        agentops.record(ActionEvent(\n            action_type="chain_start",\n            params={\n                "chain_type": serialized.get("name", "unknown"),\n                "inputs": str(inputs)[:500]  # Truncate for storage\n            }\n        ))\n\n    def on_chain_end(self, outputs, **kwargs):\n        agentops.record(ActionEvent(\n            action_type="chain_end",\n            params={"outputs": str(outputs)[:500]}\n        ))\n\n    def on_agent_action(self, action, **kwargs):\n        agentops.record(ActionEvent(\n            action_type="agent_action",\n            params={\n                "tool": action.tool,\n                "tool_input": str(action.tool_input)[:500],\n                "log": action.log[:200]\n            }\n        ))\n\n    def on_tool_error(self, error, **kwargs):\n        agentops.record(ActionEvent(\n            action_type="tool_error",\n            params={\n                "error_type": type(error).__name__,\n                "error_message": str(error)\n            }\n        ))\n\n# Use the callback\nexecutor = AgentExecutor(\n    agent=agent,\n    tools=tools,\n    callbacks=[AgentOpsCallback()]\n)\n'})}),"\n",(0,a.jsx)(n.h3,{id:"tracking-rag-pipelines",children:"Tracking RAG Pipelines"}),"\n",(0,a.jsx)(n.p,{children:"For Retrieval-Augmented Generation:"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:'from langchain.vectorstores import Chroma\nfrom langchain.embeddings import OpenAIEmbeddings\nfrom langchain.chains import RetrievalQA\n\n# Initialize with AgentOps tracking\nagentops.init(api_key="your-api-key")\n\n# Create your RAG pipeline\nembeddings = OpenAIEmbeddings()\nvectorstore = Chroma(embedding_function=embeddings)\n\n# Track retrieval metrics\nclass TrackedRetriever:\n    def __init__(self, retriever):\n        self.retriever = retriever\n\n    def get_relevant_documents(self, query: str):\n        start_time = time.time()\n\n        docs = self.retriever.get_relevant_documents(query)\n\n        agentops.record(ActionEvent(\n            action_type="retrieval",\n            params={\n                "query": query,\n                "num_docs_retrieved": len(docs),\n                "latency_ms": (time.time() - start_time) * 1000,\n                "doc_sources": [doc.metadata.get("source") for doc in docs]\n            }\n        ))\n\n        return docs\n\n# Use in your chain\nqa_chain = RetrievalQA.from_chain_type(\n    llm=ChatOpenAI(),\n    retriever=TrackedRetriever(vectorstore.as_retriever())\n)\n'})}),"\n",(0,a.jsx)(n.mermaid,{value:'flowchart LR\n    subgraph "RAG Pipeline with Observability"\n        A[Query] --\x3e B[Embedding]\n        B --\x3e C[Vector Search]\n        C --\x3e D[Retrieved Docs]\n        D --\x3e E[Context Assembly]\n        E --\x3e F[LLM]\n        F --\x3e G[Response]\n\n        B -.->|Track| H[AgentOps]\n        C -.->|Track| H\n        F -.->|Track| H\n    end\n\n    style H fill:#0066FF,stroke:#3399FF,color:#fff'}),"\n",(0,a.jsx)(n.h3,{id:"multi-chain-workflows",children:"Multi-Chain Workflows"}),"\n",(0,a.jsx)(n.p,{children:"Track complex workflows with multiple chains:"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:'from langchain.chains import SequentialChain\n\n# Create multiple chains\nresearch_chain = LLMChain(llm=llm, prompt=research_prompt, output_key="research")\nanalysis_chain = LLMChain(llm=llm, prompt=analysis_prompt, output_key="analysis")\nsummary_chain = LLMChain(llm=llm, prompt=summary_prompt, output_key="summary")\n\n# Combine into sequential chain\nfull_pipeline = SequentialChain(\n    chains=[research_chain, analysis_chain, summary_chain],\n    input_variables=["topic"],\n    output_variables=["research", "analysis", "summary"]\n)\n\n# Track with custom session tags\nwith agentops.start_session(tags=["multi-chain", "research-pipeline"]):\n    result = full_pipeline.invoke({"topic": "AI in healthcare"})\n\n    # Add session-level metrics\n    agentops.record(ActionEvent(\n        action_type="pipeline_complete",\n        params={\n            "topic": "AI in healthcare",\n            "research_length": len(result["research"]),\n            "analysis_length": len(result["analysis"]),\n            "summary_length": len(result["summary"])\n        }\n    ))\n'})}),"\n",(0,a.jsx)(n.h2,{id:"debugging-common-issues",children:"Debugging Common Issues"}),"\n",(0,a.jsx)(n.h3,{id:"issue-1-agent-loops",children:"Issue 1: Agent Loops"}),"\n",(0,a.jsx)(n.p,{children:"When your agent gets stuck in a loop:"}),"\n",(0,a.jsx)(n.mermaid,{value:"flowchart LR\n    A[Detect Loop] --\x3e B{Loop Count > 3?}\n    B --\x3e|Yes| C[Alert in AgentOps]\n    B --\x3e|No| D[Continue]\n    C --\x3e E[Review in Dashboard]\n    E --\x3e F[Identify Pattern]\n    F --\x3e G[Fix Prompt/Tools]\n\n    style C fill:#EF4444,stroke:#DC2626,color:#fff"}),"\n",(0,a.jsx)(n.p,{children:"AgentOps shows you:"}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsx)(n.li,{children:"The exact sequence of tool calls"}),"\n",(0,a.jsx)(n.li,{children:"What inputs triggered the loop"}),"\n",(0,a.jsx)(n.li,{children:"How many iterations occurred"}),"\n"]}),"\n",(0,a.jsx)(n.h3,{id:"issue-2-high-latency",children:"Issue 2: High Latency"}),"\n",(0,a.jsx)(n.p,{children:"Identify bottlenecks in your chain:"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:'# AgentOps automatically tracks timing, but you can add custom spans\nwith agentops.start_span("custom_processing"):\n    # Your slow operation\n    processed_data = expensive_operation(data)\n\n# In the dashboard, you\'ll see timing breakdown:\n# - LLM calls: 2.5s\n# - Tool executions: 1.2s\n# - Custom processing: 0.8s\n# - Other: 0.1s\n'})}),"\n",(0,a.jsx)(n.h3,{id:"issue-3-unexpected-costs",children:"Issue 3: Unexpected Costs"}),"\n",(0,a.jsx)(n.p,{children:"Track costs in real-time:"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:'# Set up cost alerts\nagentops.init(\n    api_key="your-api-key",\n    tags=["production"],\n    # Get alerted if session cost exceeds $1\n    max_session_cost=1.0\n)\n'})}),"\n",(0,a.jsx)(n.h2,{id:"best-practices",children:"Best Practices"}),"\n",(0,a.jsx)(n.h3,{id:"1-use-meaningful-tags",children:"1. Use Meaningful Tags"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:'agentops.init(api_key="your-api-key")\n\n# Start sessions with descriptive tags\nwith agentops.start_session(tags=[\n    "customer-support",\n    "tier-enterprise",\n    f"user-{user_id}",\n    f"version-{app_version}"\n]):\n    result = agent.run(user_query)\n'})}),"\n",(0,a.jsx)(n.h3,{id:"2-record-business-events",children:"2. Record Business Events"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:'# Track business-relevant events, not just technical ones\nagentops.record(ActionEvent(\n    action_type="customer_intent",\n    params={\n        "intent": "refund_request",\n        "sentiment": "frustrated",\n        "priority": "high"\n    }\n))\n'})}),"\n",(0,a.jsx)(n.h3,{id:"3-set-up-alerts",children:"3. Set Up Alerts"}),"\n",(0,a.jsx)(n.p,{children:"Configure alerts for:"}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsx)(n.li,{children:"Cost exceeding thresholds"}),"\n",(0,a.jsx)(n.li,{children:"Error rate spikes"}),"\n",(0,a.jsx)(n.li,{children:"Latency increases"}),"\n",(0,a.jsx)(n.li,{children:"Agent loop detection"}),"\n"]}),"\n",(0,a.jsx)(n.h2,{id:"real-world-example",children:"Real-World Example"}),"\n",(0,a.jsx)(n.p,{children:"Here's a complete example of a production-ready LangChain agent with full observability:"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:'import agentops\nfrom langchain.agents import create_openai_functions_agent, AgentExecutor\nfrom langchain_openai import ChatOpenAI\nfrom langchain.tools import tool\nfrom langchain.prompts import ChatPromptTemplate, MessagesPlaceholder\n\n# Initialize AgentOps\nagentops.init(\n    api_key="your-api-key",\n    default_tags=["production", "customer-support"]\n)\n\n# Define tools with clear descriptions\n@tool\ndef search_knowledge_base(query: str) -> str:\n    """Search our knowledge base for relevant articles."""\n    results = kb_client.search(query, limit=3)\n    return "\\n".join([r.content for r in results])\n\n@tool\ndef get_customer_info(customer_id: str) -> str:\n    """Get customer information including plan and history."""\n    customer = db.get_customer(customer_id)\n    return f"Name: {customer.name}, Plan: {customer.plan}, Since: {customer.created_at}"\n\n@tool\ndef create_support_ticket(title: str, description: str, priority: str) -> str:\n    """Create a support ticket for issues that need human attention."""\n    ticket = ticketing.create(title=title, description=description, priority=priority)\n\n    agentops.record(ActionEvent(\n        action_type="ticket_created",\n        params={"ticket_id": ticket.id, "priority": priority}\n    ))\n\n    return f"Ticket created: {ticket.id}"\n\n# Create agent\ntools = [search_knowledge_base, get_customer_info, create_support_ticket]\nprompt = ChatPromptTemplate.from_messages([\n    ("system", "You are a helpful customer support agent."),\n    ("human", "{input}"),\n    MessagesPlaceholder(variable_name="agent_scratchpad")\n])\n\nllm = ChatOpenAI(model="gpt-4", temperature=0)\nagent = create_openai_functions_agent(llm, tools, prompt)\nexecutor = AgentExecutor(agent=agent, tools=tools, verbose=True)\n\n# Run with session tracking\ndef handle_customer_query(customer_id: str, query: str):\n    with agentops.start_session(tags=[f"customer-{customer_id}"]):\n        try:\n            result = executor.invoke({\n                "input": f"Customer ID: {customer_id}\\nQuery: {query}"\n            })\n\n            agentops.record(ActionEvent(\n                action_type="query_resolved",\n                params={\n                    "customer_id": customer_id,\n                    "resolution_type": "automated"\n                }\n            ))\n\n            agentops.end_session(end_state="Success")\n            return result["output"]\n\n        except Exception as e:\n            agentops.end_session(end_state="Fail", end_state_reason=str(e))\n            raise\n'})}),"\n",(0,a.jsx)(n.hr,{}),"\n",(0,a.jsx)(n.p,{children:(0,a.jsxs)(n.em,{children:["Ready to add observability to your LangChain agents? ",(0,a.jsx)(n.a,{href:"/docs/getting-started/quickstart",children:"Get started free"})," and see what your agents are really doing."]})})]})}function d(e={}){const{wrapper:n}={...(0,i.R)(),...e.components};return n?(0,a.jsx)(n,{...e,children:(0,a.jsx)(p,{...e})}):p(e)}},8453(e,n,t){t.d(n,{R:()=>r,x:()=>o});var s=t(6540);const a={},i=s.createContext(a);function r(e){const n=s.useContext(i);return s.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function o(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(a):e.components||a:r(e.components),s.createElement(i.Provider,{value:n},e.children)}}}]);