"use strict";(globalThis.webpackChunkagentops_docs=globalThis.webpackChunkagentops_docs||[]).push([[279],{2776(e,n,t){t.r(n),t.d(n,{assets:()=>l,contentTitle:()=>o,default:()=>p,frontMatter:()=>a,metadata:()=>r,toc:()=>c});const r=JSON.parse('{"id":"integrations/overview","title":"Overview","description":"AgentOps integrations with popular AI frameworks","source":"@site/docs/integrations/overview.md","sourceDirName":"integrations","slug":"/integrations/overview","permalink":"/docusaurus-guide-3/docs/integrations/overview","draft":false,"unlisted":false,"editUrl":"https://github.com/agentops/agentops-docs/tree/main/docs/integrations/overview.md","tags":[],"version":"current","sidebarPosition":1,"frontMatter":{"sidebar_position":1,"title":"Overview","description":"AgentOps integrations with popular AI frameworks"},"sidebar":"docsSidebar","previous":{"title":"Cost Tracking","permalink":"/docusaurus-guide-3/docs/features/cost-tracking"},"next":{"title":"OpenAI","permalink":"/docusaurus-guide-3/docs/integrations/openai"}}');var i=t(4848),s=t(8453);const a={sidebar_position:1,title:"Overview",description:"AgentOps integrations with popular AI frameworks"},o="Integrations Overview",l={},c=[{value:"Supported Providers",id:"supported-providers",level:2},{value:"LLM Providers",id:"llm-providers",level:3},{value:"Agent Frameworks",id:"agent-frameworks",level:3},{value:"How Integration Works",id:"how-integration-works",level:2},{value:"Auto-Instrumentation",id:"auto-instrumentation",level:3},{value:"What Gets Captured",id:"what-gets-captured",level:3},{value:"Quick Start by Provider",id:"quick-start-by-provider",level:2},{value:"OpenAI",id:"openai",level:3},{value:"Anthropic",id:"anthropic",level:3},{value:"LangChain",id:"langchain",level:3},{value:"CrewAI",id:"crewai",level:3},{value:"Integration Levels",id:"integration-levels",level:2},{value:"Level 1: Basic (Auto-Instrumented)",id:"level-1-basic-auto-instrumented",level:3},{value:"Level 2: Enhanced (With Decorators)",id:"level-2-enhanced-with-decorators",level:3},{value:"Level 3: Full (Custom Events)",id:"level-3-full-custom-events",level:3},{value:"Common Patterns",id:"common-patterns",level:2},{value:"Multiple Providers",id:"multiple-providers",level:3},{value:"Async Support",id:"async-support",level:3},{value:"Streaming",id:"streaming",level:3},{value:"Disabling Auto-Instrumentation",id:"disabling-auto-instrumentation",level:2},{value:"Verifying Integration",id:"verifying-integration",level:2},{value:"Next Steps",id:"next-steps",level:2}];function d(e){const n={a:"a",code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",img:"img",li:"li",mermaid:"mermaid",p:"p",pre:"pre",strong:"strong",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",ul:"ul",...(0,s.R)(),...e.components};return(0,i.jsxs)(i.Fragment,{children:[(0,i.jsx)(n.header,{children:(0,i.jsx)(n.h1,{id:"integrations-overview",children:"Integrations Overview"})}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.img,{src:"https://images.unsplash.com/photo-1558494949-ef010cbdcc31?w=1200&h=300&fit=crop",alt:"Integrations"})}),"\n",(0,i.jsx)(n.p,{children:"AgentOps seamlessly integrates with popular AI frameworks and LLM providers, requiring minimal code changes to get full observability."}),"\n",(0,i.jsx)(n.mermaid,{value:'flowchart TB\n    subgraph Providers["LLM Providers"]\n        OpenAI[OpenAI]\n        Anthropic[Anthropic]\n        Google[Google AI]\n        Mistral[Mistral]\n        Cohere[Cohere]\n        Azure[Azure OpenAI]\n    end\n\n    subgraph Frameworks["Agent Frameworks"]\n        LangChain[LangChain]\n        CrewAI[CrewAI]\n        AutoGen[AutoGen]\n        LlamaIndex[LlamaIndex]\n    end\n\n    subgraph AgentOps["AgentOps SDK"]\n        Auto[Auto-Instrumentation]\n        Tracking[Event Tracking]\n        Analytics[Analytics]\n    end\n\n    Providers --\x3e AgentOps\n    Frameworks --\x3e AgentOps\n    AgentOps --\x3e Dashboard[Dashboard]\n\n    style OpenAI fill:#0066FF,stroke:#3399FF,color:#fff\n    style LangChain fill:#22C55E,stroke:#16A34A,color:#fff\n    style Dashboard fill:#8B5CF6,stroke:#7C3AED,color:#fff'}),"\n",(0,i.jsx)(n.h2,{id:"supported-providers",children:"Supported Providers"}),"\n",(0,i.jsx)(n.h3,{id:"llm-providers",children:"LLM Providers"}),"\n",(0,i.jsxs)(n.table,{children:[(0,i.jsx)(n.thead,{children:(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.th,{children:"Provider"}),(0,i.jsx)(n.th,{children:"Auto-Instrumented"}),(0,i.jsx)(n.th,{children:"Manual Support"})]})}),(0,i.jsxs)(n.tbody,{children:[(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"OpenAI"}),(0,i.jsx)(n.td,{children:"Yes"}),(0,i.jsx)(n.td,{children:"Yes"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"Anthropic"}),(0,i.jsx)(n.td,{children:"Yes"}),(0,i.jsx)(n.td,{children:"Yes"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"Google AI"}),(0,i.jsx)(n.td,{children:"Yes"}),(0,i.jsx)(n.td,{children:"Yes"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"Mistral"}),(0,i.jsx)(n.td,{children:"Yes"}),(0,i.jsx)(n.td,{children:"Yes"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"Cohere"}),(0,i.jsx)(n.td,{children:"Yes"}),(0,i.jsx)(n.td,{children:"Yes"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"Azure OpenAI"}),(0,i.jsx)(n.td,{children:"Yes"}),(0,i.jsx)(n.td,{children:"Yes"})]})]})]}),"\n",(0,i.jsx)(n.h3,{id:"agent-frameworks",children:"Agent Frameworks"}),"\n",(0,i.jsxs)(n.table,{children:[(0,i.jsx)(n.thead,{children:(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.th,{children:"Framework"}),(0,i.jsx)(n.th,{children:"Support Level"}),(0,i.jsx)(n.th,{children:"Features"})]})}),(0,i.jsxs)(n.tbody,{children:[(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"LangChain"}),(0,i.jsx)(n.td,{children:"Full"}),(0,i.jsx)(n.td,{children:"Chains, Agents, Tools"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"CrewAI"}),(0,i.jsx)(n.td,{children:"Full"}),(0,i.jsx)(n.td,{children:"Crews, Agents, Tasks"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"AutoGen"}),(0,i.jsx)(n.td,{children:"Full"}),(0,i.jsx)(n.td,{children:"Multi-agent conversations"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"LlamaIndex"}),(0,i.jsx)(n.td,{children:"Full"}),(0,i.jsx)(n.td,{children:"Query engines, Agents"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"Haystack"}),(0,i.jsx)(n.td,{children:"Partial"}),(0,i.jsx)(n.td,{children:"Pipelines"})]})]})]}),"\n",(0,i.jsx)(n.h2,{id:"how-integration-works",children:"How Integration Works"}),"\n",(0,i.jsx)(n.mermaid,{value:"sequenceDiagram\n    participant App as Your Application\n    participant SDK as AgentOps SDK\n    participant LLM as LLM Provider\n    participant Cloud as AgentOps Cloud\n\n    App->>SDK: agentops.init()\n    Note over SDK: Auto-instruments providers\n\n    App->>LLM: client.chat.completions.create()\n    Note over SDK: Intercepts call\n    SDK--\x3e>SDK: Record start time\n    LLM--\x3e>App: Response\n    SDK--\x3e>SDK: Calculate tokens & cost\n    SDK->>Cloud: Send event (async)\n\n    Note over Cloud: Process & store"}),"\n",(0,i.jsx)(n.h3,{id:"auto-instrumentation",children:"Auto-Instrumentation"}),"\n",(0,i.jsx)(n.p,{children:"Most providers are automatically instrumented when you initialize AgentOps:"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'import agentops\nfrom openai import OpenAI\n\n# Initialize AgentOps - auto-instruments OpenAI\nagentops.init(api_key="your-api-key")\n\n# Use OpenAI normally - all calls are tracked\nclient = OpenAI()\nresponse = client.chat.completions.create(\n    model="gpt-4",\n    messages=[{"role": "user", "content": "Hello!"}]\n)\n'})}),"\n",(0,i.jsx)(n.h3,{id:"what-gets-captured",children:"What Gets Captured"}),"\n",(0,i.jsx)(n.p,{children:"For each LLM call, AgentOps captures:"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Request details"}),": Model, messages, parameters"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Response"}),": Content, finish reason"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Tokens"}),": Input and output counts"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Timing"}),": Latency measurements"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Cost"}),": Calculated from pricing data"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Errors"}),": Any exceptions or API errors"]}),"\n"]}),"\n",(0,i.jsx)(n.h2,{id:"quick-start-by-provider",children:"Quick Start by Provider"}),"\n",(0,i.jsx)(n.h3,{id:"openai",children:"OpenAI"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'import agentops\nfrom openai import OpenAI\n\nagentops.init(api_key="your-api-key")\nclient = OpenAI()\n\n# Automatically tracked\nresponse = client.chat.completions.create(\n    model="gpt-4",\n    messages=[{"role": "user", "content": "Hello!"}]\n)\n'})}),"\n",(0,i.jsx)(n.h3,{id:"anthropic",children:"Anthropic"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'import agentops\nfrom anthropic import Anthropic\n\nagentops.init(api_key="your-api-key")\nclient = Anthropic()\n\n# Automatically tracked\nmessage = client.messages.create(\n    model="claude-3-opus-20240229",\n    max_tokens=1024,\n    messages=[{"role": "user", "content": "Hello!"}]\n)\n'})}),"\n",(0,i.jsx)(n.h3,{id:"langchain",children:"LangChain"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'import agentops\nfrom langchain_openai import ChatOpenAI\nfrom langchain.agents import initialize_agent, Tool\n\nagentops.init(api_key="your-api-key")\n\nllm = ChatOpenAI(model="gpt-4")\ntools = [...]\nagent = initialize_agent(tools, llm, agent="zero-shot-react-description")\n\n# All agent activity tracked\nresult = agent.run("What is 25 * 4?")\n'})}),"\n",(0,i.jsx)(n.h3,{id:"crewai",children:"CrewAI"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'import agentops\nfrom crewai import Agent, Task, Crew\n\nagentops.init(api_key="your-api-key")\n\nagent = Agent(\n    role="Researcher",\n    goal="Research topics",\n    backstory="Expert researcher"\n)\n\ncrew = Crew(agents=[agent], tasks=[...])\n\n# Crew execution tracked\nresult = crew.kickoff()\n'})}),"\n",(0,i.jsx)(n.h2,{id:"integration-levels",children:"Integration Levels"}),"\n",(0,i.jsx)(n.h3,{id:"level-1-basic-auto-instrumented",children:"Level 1: Basic (Auto-Instrumented)"}),"\n",(0,i.jsx)(n.p,{children:"Just initialize AgentOps and use your providers normally:"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'import agentops\nagentops.init(api_key="your-api-key")\n\n# All supported providers now tracked automatically\n'})}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.strong,{children:"What you get:"})}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"LLM call logging"}),"\n",(0,i.jsx)(n.li,{children:"Token counting"}),"\n",(0,i.jsx)(n.li,{children:"Cost tracking"}),"\n",(0,i.jsx)(n.li,{children:"Basic error capture"}),"\n"]}),"\n",(0,i.jsx)(n.h3,{id:"level-2-enhanced-with-decorators",children:"Level 2: Enhanced (With Decorators)"}),"\n",(0,i.jsx)(n.p,{children:"Add decorators for tool and agent tracking:"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'import agentops\nfrom agentops import track_agent, tool\n\nagentops.init(api_key="your-api-key")\n\n@track_agent(name="MyAgent")\nclass MyAgent:\n    @tool(name="search")\n    def search(self, query):\n        # Tool calls tracked\n        pass\n'})}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.strong,{children:"Additional features:"})}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"Tool execution tracking"}),"\n",(0,i.jsx)(n.li,{children:"Agent lifecycle events"}),"\n",(0,i.jsx)(n.li,{children:"Custom event correlation"}),"\n"]}),"\n",(0,i.jsx)(n.h3,{id:"level-3-full-custom-events",children:"Level 3: Full (Custom Events)"}),"\n",(0,i.jsx)(n.p,{children:"Add custom events for complete observability:"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'import agentops\nfrom agentops import Event\n\nagentops.init(api_key="your-api-key")\n\n# Log custom business events\nagentops.record(Event(\n    event_type="user_feedback",\n    params={"rating": 5, "comment": "Great!"}\n))\n'})}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.strong,{children:"Complete feature set:"})}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"Business event tracking"}),"\n",(0,i.jsx)(n.li,{children:"Custom metrics"}),"\n",(0,i.jsx)(n.li,{children:"Advanced analytics"}),"\n"]}),"\n",(0,i.jsx)(n.h2,{id:"common-patterns",children:"Common Patterns"}),"\n",(0,i.jsx)(n.h3,{id:"multiple-providers",children:"Multiple Providers"}),"\n",(0,i.jsx)(n.p,{children:"Use multiple LLM providers in one session:"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'import agentops\nfrom openai import OpenAI\nfrom anthropic import Anthropic\n\nagentops.init(api_key="your-api-key")\n\nopenai_client = OpenAI()\nanthropic_client = Anthropic()\n\n# Both are tracked in the same session\ngpt_response = openai_client.chat.completions.create(...)\nclaude_response = anthropic_client.messages.create(...)\n'})}),"\n",(0,i.jsx)(n.h3,{id:"async-support",children:"Async Support"}),"\n",(0,i.jsx)(n.p,{children:"All integrations support async operations:"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'import agentops\nimport asyncio\nfrom openai import AsyncOpenAI\n\nagentops.init(api_key="your-api-key")\n\nasync def main():\n    client = AsyncOpenAI()\n\n    # Async calls tracked\n    response = await client.chat.completions.create(\n        model="gpt-4",\n        messages=[{"role": "user", "content": "Hello!"}]\n    )\n\nasyncio.run(main())\n'})}),"\n",(0,i.jsx)(n.h3,{id:"streaming",children:"Streaming"}),"\n",(0,i.jsx)(n.p,{children:"Streaming responses are fully supported:"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'import agentops\nfrom openai import OpenAI\n\nagentops.init(api_key="your-api-key")\nclient = OpenAI()\n\n# Streaming tracked - event recorded after stream completes\nstream = client.chat.completions.create(\n    model="gpt-4",\n    messages=[{"role": "user", "content": "Tell me a story"}],\n    stream=True\n)\n\nfor chunk in stream:\n    print(chunk.choices[0].delta.content or "", end="")\n'})}),"\n",(0,i.jsx)(n.h2,{id:"disabling-auto-instrumentation",children:"Disabling Auto-Instrumentation"}),"\n",(0,i.jsx)(n.p,{children:"If needed, disable specific instrumentations:"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'import agentops\n\nagentops.init(\n    api_key="your-api-key",\n    instrument_llm_calls=False  # Disable all auto-instrumentation\n)\n'})}),"\n",(0,i.jsx)(n.h2,{id:"verifying-integration",children:"Verifying Integration"}),"\n",(0,i.jsx)(n.p,{children:"Check that integration is working:"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'import agentops\n\nagentops.init(api_key="your-api-key")\n\n# Make a test call\nfrom openai import OpenAI\nclient = OpenAI()\nresponse = client.chat.completions.create(\n    model="gpt-3.5-turbo",\n    messages=[{"role": "user", "content": "Test"}]\n)\n\n# Check the dashboard for the recorded event\nagentops.end_session(end_state="Success")\nprint("Check dashboard for test session")\n'})}),"\n",(0,i.jsx)(n.h2,{id:"next-steps",children:"Next Steps"}),"\n",(0,i.jsx)(n.p,{children:"Choose your integration guide:"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:(0,i.jsx)(n.a,{href:"/docs/integrations/openai",children:"OpenAI"})}),"\n",(0,i.jsx)(n.li,{children:(0,i.jsx)(n.a,{href:"/docs/integrations/anthropic",children:"Anthropic"})}),"\n",(0,i.jsx)(n.li,{children:(0,i.jsx)(n.a,{href:"/docs/integrations/langchain",children:"LangChain"})}),"\n",(0,i.jsx)(n.li,{children:(0,i.jsx)(n.a,{href:"/docs/integrations/crewai",children:"CrewAI"})}),"\n",(0,i.jsx)(n.li,{children:(0,i.jsx)(n.a,{href:"/docs/integrations/autogen",children:"AutoGen"})}),"\n",(0,i.jsx)(n.li,{children:(0,i.jsx)(n.a,{href:"/docs/integrations/llama-index",children:"LlamaIndex"})}),"\n"]})]})}function p(e={}){const{wrapper:n}={...(0,s.R)(),...e.components};return n?(0,i.jsx)(n,{...e,children:(0,i.jsx)(d,{...e})}):d(e)}},8453(e,n,t){t.d(n,{R:()=>a,x:()=>o});var r=t(6540);const i={},s=r.createContext(i);function a(e){const n=r.useContext(s);return r.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function o(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(i):e.components||i:a(e.components),r.createElement(s.Provider,{value:n},e.children)}}}]);